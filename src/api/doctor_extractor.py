"""
Ø³Ø±ÙˆÛŒØ³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø§Ø² Ù„ÛŒÙ†Ú© Ù¾Ø°ÛŒØ±Ø´24
"""
import httpx
import json
import re
import logging
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse, unquote
from datetime import datetime
import time
import random

logger = logging.getLogger(__name__)


class DoctorExtractor:
    """Ú©Ù„Ø§Ø³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø§Ø² ØµÙØ­Ù‡ Ù¾Ø°ÛŒØ±Ø´24"""
    
    def __init__(self, timeout: int = 30):
        self.timeout = timeout
        self.base_url = "https://www.paziresh24.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'fa-IR,fa;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0'
        }
    
    def normalize_doctor_url(self, url: str) -> str:
        """Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ URL Ø¯Ú©ØªØ±"""
        try:
            # Ø­Ø°Ù ÙØ¶Ø§Ù‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
            url = url.strip()
            
            # Ø§Ú¯Ø± ÙÙ‚Ø· slug Ø§Ø³Øª
            if url.startswith('dr/') or url.startswith('/dr/'):
                url = url.lstrip('/')
                return f"{self.base_url}/{url}"
            
            # Ø§Ú¯Ø± URL Ú©Ø§Ù…Ù„ Ø§Ø³Øª
            if url.startswith('http'):
                parsed = urlparse(url)
                if 'paziresh24.com' in parsed.netloc:
                    return url
                else:
                    raise ValueError("URL Ø¨Ø§ÛŒØ¯ Ø§Ø² Ø¯Ø§Ù…Ù†Ù‡ paziresh24.com Ø¨Ø§Ø´Ø¯")
            
            # Ø§Ú¯Ø± ÙÙ‚Ø· slug Ø¨Ø¯ÙˆÙ† dr/ Ø§Ø³Øª
            if not url.startswith('dr/'):
                url = f"dr/{url}"
            
            return f"{self.base_url}/{url}"
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ URL: {e}")
            raise ValueError(f"URL Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {url}")
    
    def extract_slug_from_url(self, url: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ slug Ø§Ø² URL"""
        try:
            normalized_url = self.normalize_doctor_url(url)
            parsed = urlparse(normalized_url)
            path = parsed.path
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ slug Ø§Ø² path
            # Ù…Ø«Ø§Ù„: /dr/Ø¯Ú©ØªØ±-Ø³ÛŒØ¯Ù…Ø­Ù…Ø¯Ù…Ø¬ØªØ¨ÛŒ-Ù…ÙˆØ³ÙˆÛŒ-0/
            if '/dr/' in path:
                slug_part = path.split('/dr/')[-1].rstrip('/')
                # URL decode Ú©Ø±Ø¯Ù†
                slug = unquote(slug_part)
                return slug
            else:
                raise ValueError("URL Ø´Ø§Ù…Ù„ /dr/ Ù†ÛŒØ³Øª")
                
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ slug: {e}")
            raise ValueError(f"Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù† slug Ø±Ø§ Ø§Ø² URL Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø±Ø¯: {url}")
    
    async def fetch_doctor_page(self, url: str) -> str:
        """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡ Ø¯Ú©ØªØ±"""
        try:
            normalized_url = self.normalize_doctor_url(url)
            logger.info(f"ğŸ” Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {normalized_url}")
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.get(normalized_url, headers=self.headers)
                response.raise_for_status()
                
                if response.status_code != 200:
                    raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {response.status_code}")
                
                content = response.text
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ __NEXT_DATA__
                if '__NEXT_DATA__' not in content:
                    raise ValueError("ØµÙØ­Ù‡ Ø¯Ú©ØªØ± Ù…Ø¹ØªØ¨Ø± Ù†ÛŒØ³Øª - __NEXT_DATA__ ÛŒØ§ÙØª Ù†Ø´Ø¯")
                
                logger.info(f"âœ… ØµÙØ­Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ ({len(content)} Ú©Ø§Ø±Ø§Ú©ØªØ±)")
                return content
                
        except httpx.TimeoutException:
            raise ValueError("Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ ØªÙ…Ø§Ù… Ø´Ø¯")
        except httpx.HTTPStatusError as e:
            if e.response.status_code == 404:
                raise ValueError("ØµÙØ­Ù‡ Ø¯Ú©ØªØ± ÛŒØ§ÙØª Ù†Ø´Ø¯ (404)")
            else:
                raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {e.response.status_code}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {e}")
            raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {str(e)}")
    
    def extract_next_data(self, html_content: str) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ __NEXT_DATA__ Ø§Ø² HTML"""
        try:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† script tag Ø­Ø§ÙˆÛŒ __NEXT_DATA__
            pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
            match = re.search(pattern, html_content, re.DOTALL)
            
            if not match:
                raise ValueError("__NEXT_DATA__ Ø¯Ø± ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            json_str = match.group(1)
            
            # Parse Ú©Ø±Ø¯Ù† JSON
            next_data = json.loads(json_str)
            
            logger.info("âœ… __NEXT_DATA__ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯")
            return next_data
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± parse Ú©Ø±Ø¯Ù† JSON: {e}")
            raise ValueError("Ø®Ø·Ø§ Ø¯Ø± parse Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØµÙØ­Ù‡")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ __NEXT_DATA__: {e}")
            raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª: {str(e)}")
    
    def parse_doctor_data(self, next_data: Dict) -> Dict:
        """ØªØ¬Ø²ÛŒÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø§Ø² __NEXT_DATA__"""
        try:
            page_props = next_data.get('props', {}).get('pageProps', {})
            
            # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ Ø¯Ú©ØªØ±
            information = page_props.get('information', {})
            centers_data = page_props.get('centers', [])
            expertises = page_props.get('expertises', {})
            
            if not information:
                raise ValueError("Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø¯Ø± ØµÙØ­Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ
            doctor_info = {
                'doctor_id': information.get('id'),
                'name': information.get('display_name') or f"{information.get('name', '')} {information.get('family', '')}".strip(),
                'first_name': information.get('name'),
                'last_name': information.get('family'),
                'provider_id': information.get('provider_id'),
                'user_id': information.get('user_id'),
                'server_id': information.get('server_id', 1),
                'biography': information.get('biography', ''),
                'image_url': information.get('image', ''),
                'slug': page_props.get('slug', ''),
                'specialty': self._extract_specialty(expertises),
                'centers': []
            }
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø§Ú©Ø²
            for center_data in centers_data:
                center_info = {
                    'center_id': center_data.get('id'),
                    'center_name': center_data.get('name'),
                    'center_type': center_data.get('center_type_name'),
                    'center_address': center_data.get('address'),
                    'center_phone': center_data.get('tell'),
                    'user_center_id': center_data.get('user_center_id'),
                    'services': []
                }
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§
                for service_data in center_data.get('services', []):
                    service_info = {
                        'service_id': service_data.get('id'),
                        'service_name': service_data.get('alias_title', 'ÙˆÛŒØ²ÛŒØª'),
                        'user_center_id': service_data.get('user_center_id'),
                        'price': service_data.get('free_price', 0),
                        'duration': service_data.get('duration', ''),
                    }
                    center_info['services'].append(service_info)
                
                doctor_info['centers'].append(center_info)
            
            # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ
            if not doctor_info['doctor_id']:
                raise ValueError("Ø´Ù†Ø§Ø³Ù‡ Ø¯Ú©ØªØ± ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            if not doctor_info['name']:
                raise ValueError("Ù†Ø§Ù… Ø¯Ú©ØªØ± ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            if not doctor_info['centers']:
                raise ValueError("Ù‡ÛŒÚ† Ù…Ø±Ú©Ø² Ø¯Ø±Ù…Ø§Ù†ÛŒ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø¯Ú©ØªØ± ÛŒØ§ÙØª Ù†Ø´Ø¯")
            
            # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ù‡Ø± Ù…Ø±Ú©Ø²
            for center in doctor_info['centers']:
                if not center['services']:
                    logger.warning(f"âš ï¸ Ù…Ø±Ú©Ø² {center['center_name']} Ù‡ÛŒÚ† Ø³Ø±ÙˆÛŒØ³ÛŒ Ù†Ø¯Ø§Ø±Ø¯")
            
            logger.info(f"âœ… Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± {doctor_info['name']} Ø¨Ø§ {len(doctor_info['centers'])} Ù…Ø±Ú©Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯")
            return doctor_info
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¬Ø²ÛŒÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ±: {e}")
            raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ¬Ø²ÛŒÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ±: {str(e)}")
    
    def _extract_specialty(self, expertises: Dict) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ®ØµØµ Ø¯Ú©ØªØ±"""
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² expertises
            expertises_list = expertises.get('expertises', [])
            if expertises_list:
                # ØªØ±Ú©ÛŒØ¨ ØªÙ…Ø§Ù… ØªØ®ØµØµâ€ŒÙ‡Ø§
                specialties = []
                for exp in expertises_list:
                    alias_title = exp.get('alias_title', '')
                    if alias_title:
                        specialties.append(alias_title)
                
                if specialties:
                    return ', '.join(specialties)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² group_expertises
            group_expertises = expertises.get('group_expertises', [])
            if group_expertises:
                group_names = [group.get('name', '') for group in group_expertises if group.get('name')]
                if group_names:
                    return ', '.join(group_names)
            
            return 'Ø¹Ù…ÙˆÙ…ÛŒ'
            
        except Exception as e:
            logger.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ®ØµØµ: {e}")
            return 'Ø¹Ù…ÙˆÙ…ÛŒ'
    
    def generate_terminal_id(self) -> str:
        """ØªÙˆÙ„ÛŒØ¯ terminal_id"""
        try:
            # Ø§Ù„Ú¯ÙˆÛŒ terminal_id: clinic-{timestamp}.{random}
            timestamp = str(int(time.time() * 1000))[-12:]  # 12 Ø±Ù‚Ù… Ø¢Ø®Ø± timestamp
            random_part = str(random.randint(10000000, 99999999))  # 8 Ø±Ù‚Ù… ØªØµØ§Ø¯ÙÛŒ
            
            terminal_id = f"clinic-{timestamp}.{random_part}"
            logger.debug(f"ğŸ”§ terminal_id ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {terminal_id}")
            return terminal_id
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ terminal_id: {e}")
            # fallback
            return f"clinic-{int(time.time())}.{random.randint(10000000, 99999999)}"
    
    async def extract_doctor_from_url(self, url: str) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø§Ø² URL"""
        try:
            logger.info(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ± Ø§Ø²: {url}")
            
            # 1. Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ URL Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ slug
            normalized_url = self.normalize_doctor_url(url)
            slug = self.extract_slug_from_url(url)
            
            # 2. Ø¯Ø±ÛŒØ§ÙØª Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡
            html_content = await self.fetch_doctor_page(normalized_url)
            
            # 3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ __NEXT_DATA__
            next_data = self.extract_next_data(html_content)
            
            # 4. ØªØ¬Ø²ÛŒÙ‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ±
            doctor_data = self.parse_doctor_data(next_data)
            
            # 5. Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
            doctor_data['original_url'] = normalized_url
            doctor_data['extracted_slug'] = slug
            doctor_data['terminal_id'] = self.generate_terminal_id()
            doctor_data['extraction_time'] = datetime.utcnow().isoformat()
            
            logger.info(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ø§Ù…Ù„ Ø´Ø¯: {doctor_data['name']} ({len(doctor_data['centers'])} Ù…Ø±Ú©Ø²)")
            return doctor_data
            
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ±: {e}")
            raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ú©ØªØ±: {str(e)}")


# ØªØ³Øª Ø³Ø±ÛŒØ¹
async def test_extractor():
    """ØªØ³Øª Ø³Ø±ÛŒØ¹ extractor"""
    extractor = DoctorExtractor()
    
    test_urls = [
        "dr/Ø¯Ú©ØªØ±-Ø³ÛŒØ¯Ù…Ø­Ù…Ø¯Ù…Ø¬ØªØ¨ÛŒ-Ù…ÙˆØ³ÙˆÛŒ-0/",
        "https://www.paziresh24.com/dr/%D8%AF%DA%A9%D8%AA%D8%B1-%D8%B3%DB%8C%D8%AF%D9%85%D8%AD%D9%85%D8%AF%D9%85%D8%AC%D8%AA%D8%A8%DB%8C-%D9%85%D9%88%D8%B3%D9%88%DB%8C-0/"
    ]
    
    for url in test_urls:
        try:
            print(f"\nğŸ” ØªØ³Øª URL: {url}")
            result = await extractor.extract_doctor_from_url(url)
            print(f"âœ… Ù†Ø§Ù…: {result['name']}")
            print(f"âœ… ØªØ®ØµØµ: {result['specialty']}")
            print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ù…Ø±Ø§Ú©Ø²: {len(result['centers'])}")
            for center in result['centers']:
                print(f"  - {center['center_name']} ({len(center['services'])} Ø³Ø±ÙˆÛŒØ³)")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§: {e}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_extractor())