# P24_SlotHunter - Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ ØªÙˆØ³Ø¹Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡

## ğŸ“‹ Ø®Ù„Ø§ØµÙ‡ Ù¾Ø±ÙˆÚ˜Ù‡

**Ù‡Ø¯Ù:** ØªÙˆØ³Ø¹Ù‡ Ø±Ø¨Ø§Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ù†Ø¸Ø§Ø±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ø¨Ø± Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¯Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ø®Øµ Ø¯Ø± Ø³Ø§ÛŒØª Ù¾Ø°ÛŒØ±Ø´Û²Û´ Ùˆ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ ÙÙˆØ±ÛŒ Ø§Ø² Ø·Ø±ÛŒÙ‚ ØªÙ„Ú¯Ø±Ø§Ù…

**Ù…Ø­Ø¯ÙˆØ¯Ù‡:** Û²-Û³ Ø¯Ú©ØªØ± (Ø¨Ø±Ø§ÛŒ Ø­Ø¯Ø§Ú©Ø«Ø± Ø³Ø±Ø¹Øª Ùˆ Ú©Ø§Ø±Ø§ÛŒÛŒ)  
**Ø³Ø±Ø¹Øª Ù…ÙˆØ±Ø¯ Ø§Ù†ØªØ¸Ø§Ø±:** Û¹ Ø§Ø² Û±Û° (Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´: Û±-Û³ Ø«Ø§Ù†ÛŒÙ‡)  

---

## ğŸ›  ØªÚ©Ù†ÙˆÙ„ÙˆÚ˜ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ

### Core Technologies
- **Ø²Ø¨Ø§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡â€ŒÙ†ÙˆÛŒØ³ÛŒ:** Python 3.9+
- **Web Scraping:** Playwright (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¬Ø¯ÛŒØ¯) / Selenium WebDriver + BeautifulSoup
- **Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…:** python-telegram-bot v20+
- **Ø¯ÛŒØªØ§Ø¨ÛŒØ³:** SQLite (development) / PostgreSQL (production)
- **Async Processing:** asyncio + aiohttp
- **Caching:** Redis (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ Ø¬Ø¯ÛŒØ¯)
- **Monitoring:** Prometheus + Grafana (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)
- **Containerization:** Docker + Docker Compose

### Dependencies
```txt
# Core Dependencies
playwright>=1.40.0
beautifulsoup4>=4.12.0
python-telegram-bot>=20.7
asyncio
aiohttp>=3.9.0
sqlalchemy>=2.0.0
alembic>=1.13.0
redis>=5.0.0
pydantic>=2.5.0
pyyaml>=6.0.1

# Development & Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
black>=23.0.0
flake8>=6.0.0
mypy>=1.7.0

# Monitoring (Optional)
prometheus-client>=0.19.0
structlog>=23.2.0

# Production
gunicorn>=21.2.0
uvicorn>=0.24.0
```

---

## ğŸ“ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡ (Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)

```
P24_SlotHunter/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø±Ú©Ø²ÛŒ Ø¨Ø§ Pydantic
â”‚   â”‚   â”œâ”€â”€ exceptions.py          # Exception classes Ø³ÙØ§Ø±Ø´ÛŒ
â”‚   â”‚   â””â”€â”€ constants.py           # Ø«ÙˆØ§Ø¨Øª Ù¾Ø±ÙˆÚ˜Ù‡
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py        # Abstract base class
â”‚   â”‚   â”œâ”€â”€ paziresh_scraper.py    # Ù‡Ø³ØªÙ‡ Ø§ØµÙ„ÛŒ scraping
â”‚   â”‚   â”œâ”€â”€ appointment_parser.py  # Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§
â”‚   â”‚   â”œâ”€â”€ session_manager.py     # Ù…Ø¯ÛŒØ±ÛŒØª session Ùˆ cookie
â”‚   â”‚   â””â”€â”€ retry_handler.py       # Ù…Ø¯ÛŒØ±ÛŒØª retry Ùˆ circuit breaker
â”‚   â”œâ”€â”€ telegram/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bot_handler.py         # Ù…Ø¯ÛŒØ±ÛŒØª Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
â”‚   â”‚   â”œâ”€â”€ message_formatter.py   # ÙØ±Ù…Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
â”‚   â”‚   â”œâ”€â”€ user_manager.py        # Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
â”‚   â”‚   â”œâ”€â”€ keyboards.py           # Ú©ÛŒØ¨ÙˆØ±Ø¯Ù‡Ø§ÛŒ inline
â”‚   â”‚   â””â”€â”€ middleware.py          # Middleware Ø¨Ø±Ø§ÛŒ logging Ùˆ auth
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py              # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ database.py            # Ø§ØªØµØ§Ù„ Ùˆ Ø¹Ù…Ù„ÛŒØ§Øª DB
â”‚   â”‚   â”œâ”€â”€ repositories.py        # Repository pattern
â”‚   â”‚   â””â”€â”€ migrations/            # Alembic migrations
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task_scheduler.py      # Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú†Ú©â€ŒÙ‡Ø§
â”‚   â”‚   â”œâ”€â”€ job_manager.py         # Ù…Ø¯ÛŒØ±ÛŒØª job Ù‡Ø§
â”‚   â”‚   â””â”€â”€ health_checker.py      # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…
â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ redis_client.py        # Redis client
â”‚   â”‚   â””â”€â”€ cache_manager.py       # Ù…Ø¯ÛŒØ±ÛŒØª cache
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py             # Prometheus metrics
â”‚   â”‚   â”œâ”€â”€ logger.py              # Structured logging
â”‚   â”‚   â””ï¿½ï¿½ï¿½â”€ health.py              # Health check endpoints
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ helpers.py             # ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
â”‚       â”œâ”€â”€ validators.py          # Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
â”‚       â””â”€â”€ decorators.py          # Decorators Ù…ÙÛŒØ¯
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                      # ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø­Ø¯
â”‚   â”œâ”€â”€ integration/               # ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ÛŒÚ©Ù¾Ø§Ø±Ú†Ú¯ÛŒ
â”‚   â”œâ”€â”€ e2e/                       # ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ end-to-end
â”‚   â””â”€â”€ fixtures/                  # Test fixtures
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.yaml                # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ØµÙ„ÛŒ
â”‚   â”œâ”€â”€ config.dev.yaml            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª development
â”‚   â”œâ”€â”€ config.prod.yaml           # ØªÙ†Ø¸ÛŒÙ…Ø§Øª production
â”‚   â”œâ”€â”€ doctors.json               # Ù„ÛŒØ³Øª Ø¯Ú©ØªØ±Ù‡Ø§
â”‚   â””â”€â”€ logging.yaml               # ØªÙ†Ø¸ÛŒÙ…Ø§Øª logging
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile                 # Docker image Ø§ØµÙ„ÛŒ
â”‚   â”œâ”€â”€ Dockerfile.dev             # Development image
â”‚   â””â”€â”€ docker-compose.yml         # Multi-service setup
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                   # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
â”‚   â”œâ”€â”€ deploy.sh                  # Ø§Ø³Ú©Ø±ÛŒÙ¾Øª deployment
â”‚   â””â”€â”€ backup.sh                  # Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md                     # Ù…Ø³ØªÙ†Ø¯Ø§Øª API
â”‚   â”œâ”€â”€ DEPLOYMENT.md              # Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ deployment
â”‚   â””â”€â”€ TROUBLESHOOTING.md         # Ø¹ÛŒØ¨â€ŒÛŒØ§Ø¨ÛŒ
â”œâ”€â”€ requirements/
â”‚   â”œâ”€â”€ base.txt                   # Dependencies Ø§ØµÙ„ÛŒ
â”‚   â”œâ”€â”€ dev.txt                    # Development dependencies
â”‚   â””â”€â”€ prod.txt                   # Production dependencies
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml                 # Continuous Integration
â”‚       â””â”€â”€ cd.yml                 # Continuous Deployment
â”œâ”€â”€ main.py                        # Entry point Ø§ØµÙ„ÛŒ
â”œâ”€â”€ README.md
â”œâ”€â”€ CHANGELOG.md
â””â”€â”€ LICENSE
```

---

## ğŸš€ Ù…Ø±Ø§Ø­Ù„ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ (Û¶ ÙØ§Ø²)

### ğŸ“… ÙØ§Ø² Û±: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù¾Ø§ÛŒÙ‡ Ùˆ Infrastructure (Ø±ÙˆØ² Û±-Û²)

#### Û±.Û± ØªÙ†Ø¸ÛŒÙ… Ù…Ø­ÛŒØ· ØªÙˆØ³Ø¹Ù‡
- [ ] Ù†ØµØ¨ Python 3.9+ Ùˆ virtual environment
- [ ] Ù†ØµØ¨ Playwright Ùˆ browsers
- [ ] Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Redis (Docker)
- [ ] ØªÙ†Ø¸ÛŒÙ… Git hooks Ùˆ pre-commit
- [ ] Ø§ÛŒØ¬Ø§Ø¯ Ø³Ø§Ø®ØªØ§Ø± ÙÙˆÙ„Ø¯Ø±Ø¨Ù†Ø¯ÛŒ

#### Û±.Û² Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Core Infrastructure
```python
# src/core/config.py
from pydantic import BaseSettings, Field
from typing import List, Optional

class Settings(BaseSettings):
    # Telegram Bot
    telegram_bot_token: str = Field(..., env="TELEGRAM_BOT_TOKEN")
    telegram_admin_chat_id: int = Field(..., env="TELEGRAM_ADMIN_CHAT_ID")
    
    # Database
    database_url: str = Field("sqlite:///./data/appointments.db", env="DATABASE_URL")
    
    # Redis
    redis_url: str = Field("redis://localhost:6379", env="REDIS_URL")
    
    # Scraping
    check_interval: int = Field(30, description="Check interval in seconds")
    request_timeout: int = Field(10, description="Request timeout in seconds")
    max_retries: int = 3
    rate_limit: float = 0.5  # Requests per second
    
    # Monitoring
    enable_metrics: bool = Field(False, env="ENABLE_METRICS")
    log_level: str = Field("INFO", env="LOG_LEVEL")
    
    class Config:
        env_file = ".env"
        case_sensitive = False

settings = Settings()
```

#### Û±.Û³ Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Logging Ùˆ Monitoring
```python
# src/monitoring/logger.py
import structlog
from typing import Any, Dict

def setup_logging(log_level: str = "INFO") -> None:
    structlog.configure(
        processors=[
            structlog.stdlib.filter_by_level,
            structlog.stdlib.add_logger_name,
            structlog.stdlib.add_log_level,
            structlog.stdlib.PositionalArgumentsFormatter(),
            structlog.processors.TimeStamper(fmt="iso"),
            structlog.processors.StackInfoRenderer(),
            structlog.processors.format_exc_info,
            structlog.processors.UnicodeDecoder(),
            structlog.processors.JSONRenderer()
        ],
        context_class=dict,
        logger_factory=structlog.stdlib.LoggerFactory(),
        wrapper_class=structlog.stdlib.BoundLogger,
        cache_logger_on_first_use=True,
    )
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Û±:**
- Ù…Ø­ÛŒØ· ØªÙˆØ³Ø¹Ù‡ Ú©Ø§Ù…Ù„
- Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡
- Ø³ÛŒØ³ØªÙ… logging
- ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡

---

### ğŸ“… ÙØ§Ø² Û²: Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Scraper Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø±ÙˆØ² Û³-Û´)

#### Û².Û± Base Scraper Ø¨Ø§ Playwright
```python
# src/scraper/base_scraper.py
from abc import ABC, abstractmethod
from playwright.async_api import async_playwright, Browser, Page
from typing import List, Dict, Any, Optional
import asyncio

class BaseScraper(ABC):
    def __init__(self, headless: bool = True, timeout: int = 10000):
        self.headless = headless
        self.timeout = timeout
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
    
    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(
            headless=self.headless,
            args=['--no-sandbox', '--disable-dev-shm-usage']
        )
        self.page = await self.browser.new_page()
        await self.page.set_extra_http_headers({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
    
    @abstractmethod
    async def scrape_appointments(self, doctor_url: str) -> List[Dict[str, Any]]:
        pass
```

#### Û².Û² Paziresh24 Scraper
```python
# src/scraper/paziresh_scraper.py
from .base_scraper import BaseScraper
from .retry_handler import RetryHandler
from typing import List, Dict, Any
import structlog

logger = structlog.get_logger(__name__)

class PazireshScraper(BaseScraper):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.retry_handler = RetryHandler(max_retries=3, backoff_factor=2)
    
    @RetryHandler.with_retry
    async def scrape_appointments(self, doctor_url: str) -> List[Dict[str, Any]]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø² ØµÙØ­Ù‡ Ø¯Ú©ØªØ±"""
        try:
            await self.page.goto(doctor_url, wait_until='networkidle')
            
            # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„ ØµÙØ­Ù‡
            await self.page.wait_for_selector('.appointment-section', timeout=self.timeout)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
            appointments = await self.page.evaluate("""
                () => {
                    const appointments = [];
                    const slots = document.querySelectorAll('.available-slot');
                    
                    slots.forEach(slot => {
                        const date = slot.querySelector('.date')?.textContent?.trim();
                        const time = slot.querySelector('.time')?.textContent?.trim();
                        const price = slot.querySelector('.price')?.textContent?.trim();
                        
                        if (date && time) {
                            appointments.push({
                                date: date,
                                time: time,
                                price: price || 'Ù†Ø§Ù…Ø´Ø®Øµ',
                                available: true,
                                scraped_at: new Date().toISOString()
                            });
                        }
                    });
                    
                    return appointments;
                }
            """)
            
            logger.info("Appointments scraped successfully", 
                       doctor_url=doctor_url, 
                       count=len(appointments))
            
            return appointments
            
        except Exception as e:
            logger.error("Failed to scrape appointments", 
                        doctor_url=doctor_url, 
                        error=str(e))
            raise
```

#### Û².Û³ Retry Handler Ùˆ Circuit Breaker
```python
# src/scraper/retry_handler.py
import asyncio
import time
from functools import wraps
from typing import Callable, Any
import structlog

logger = structlog.get_logger(__name__)

class CircuitBreaker:
    def __init__(self, failure_threshold: int = 5, timeout: int = 60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = 'CLOSED'  # CLOSED, OPEN, HALF_OPEN
    
    def can_execute(self) -> bool:
        if self.state == 'CLOSED':
            return True
        elif self.state == 'OPEN':
            if time.time() - self.last_failure_time > self.timeout:
                self.state = 'HALF_OPEN'
                return True
            return False
        else:  # HALF_OPEN
            return True
    
    def record_success(self):
        self.failure_count = 0
        self.state = 'CLOSED'
    
    def record_failure(self):
        self.failure_count += 1
        self.last_failure_time = time.time()
        if self.failure_count >= self.failure_threshold:
            self.state = 'OPEN'

class RetryHandler:
    def __init__(self, max_retries: int = 3, backoff_factor: float = 2):
        self.max_retries = max_retries
        self.backoff_factor = backoff_factor
        self.circuit_breaker = CircuitBreaker()
    
    @staticmethod
    def with_retry(func: Callable) -> Callable:
        @wraps(func)
        async def wrapper(self, *args, **kwargs) -> Any:
            if not self.retry_handler.circuit_breaker.can_execute():
                raise Exception("Circuit breaker is OPEN")
            
            last_exception = None
            for attempt in range(self.retry_handler.max_retries + 1):
                try:
                    result = await func(self, *args, **kwargs)
                    self.retry_handler.circuit_breaker.record_success()
                    return result
                except Exception as e:
                    last_exception = e
                    if attempt < self.retry_handler.max_retries:
                        wait_time = self.retry_handler.backoff_factor ** attempt
                        logger.warning(f"Attempt {attempt + 1} failed, retrying in {wait_time}s", 
                                     error=str(e))
                        await asyncio.sleep(wait_time)
                    else:
                        self.retry_handler.circuit_breaker.record_failure()
            
            raise last_exception
        return wrapper
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Û²:**
- Scraper Ú©Ø§Ù…Ù„ Ø¨Ø§ Playwright
- Ø³ÛŒØ³ØªÙ… retry Ùˆ circuit breaker
- ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ scraping Ø±ÙˆÛŒ Û± Ø¯Ú©ØªØ±
- Ø§Ù†Ø¯Ø§Ø²Ù‡â€ŒÚ¯ÛŒØ±ÛŒ performance

---

### ğŸ“… ÙØ§Ø² Û³: ØªÙˆØ³Ø¹Ù‡ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ù¾ÛŒØ´Ø±ÙØªÙ‡ (Ø±ÙˆØ² Ûµ-Û¶)

#### Û³.Û± Bot Handler Ø¨Ø§ Middleware
```python
# src/telegram/bot_handler.py
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, CallbackQueryHandler, ContextTypes
from .middleware import LoggingMiddleware, AuthMiddleware
from .user_manager import UserManager
from .message_formatter import MessageFormatter
import structlog

logger = structlog.get_logger(__name__)

class TelegramBot:
    def __init__(self, token: str, user_manager: UserManager):
        self.token = token
        self.user_manager = user_manager
        self.formatter = MessageFormatter()
        self.app = None
    
    async def setup(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª Ùˆ handlers"""
        self.app = Application.builder().token(self.token).build()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† middleware
        self.app.add_handler(LoggingMiddleware())
        self.app.add_handler(AuthMiddleware(self.user_manager))
        
        # Command handlers
        self.app.add_handler(CommandHandler("start", self.start_command))
        self.app.add_handler(CommandHandler("subscribe", self.subscribe_command))
        self.app.add_handler(CommandHandler("unsubscribe", self.unsubscribe_command))
        self.app.add_handler(CommandHandler("status", self.status_command))
        self.app.add_handler(CommandHandler("help", self.help_command))
        
        # Callback handlers
        self.app.add_handler(CallbackQueryHandler(self.handle_callback))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ø¯Ø³ØªÙˆØ± Ø´Ø±ÙˆØ¹ Ú©Ø§Ø± Ø¨Ø§ Ø±Ø¨Ø§Øª"""
        user_id = update.effective_user.id
        username = update.effective_user.username
        
        # Ø«Ø¨Øª Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
        await self.user_manager.register_user(user_id, username)
        
        welcome_message = self.formatter.format_welcome_message()
        keyboard = self.formatter.get_main_keyboard()
        
        await update.message.reply_text(
            welcome_message,
            reply_markup=keyboard,
            parse_mode='HTML'
        )
    
    async def subscribe_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """Ø§Ø´ØªØ±Ø§Ú© Ø¯Ø± Ø¯Ú©ØªØ±"""
        user_id = update.effective_user.id
        
        # Ù†Ù…Ø§ÛŒØ´ Ù„ÛŒØ³Øª Ø¯Ú©ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        doctors = await self.user_manager.get_available_doctors()
        keyboard = self.formatter.get_doctors_keyboard(doctors)
        
        await update.message.reply_text(
            "ğŸ” Ù„Ø·ÙØ§Ù‹ Ø¯Ú©ØªØ± Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø± Ø®ÙˆØ¯ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯:",
            reply_markup=keyboard
        )
    
    async def notify_appointment_available(self, user_id: int, doctor_info: dict, appointment: dict):
        """Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ù†ÙˆØ¨Øª Ø®Ø§Ù„ÛŒ"""
        message = self.formatter.format_appointment_notification(doctor_info, appointment)
        keyboard = self.formatter.get_appointment_keyboard(doctor_info['url'])
        
        try:
            await self.app.bot.send_message(
                chat_id=user_id,
                text=message,
                reply_markup=keyboard,
                parse_mode='HTML'
            )
            logger.info("Notification sent successfully", user_id=user_id)
        except Exception as e:
            logger.error("Failed to send notification", user_id=user_id, error=str(e))
```

#### Û³.Û² Message Formatter
```python
# src/telegram/message_formatter.py
from telegram import InlineKeyboardButton, InlineKeyboardMarkup
from typing import Dict, List, Any
from datetime import datetime

class MessageFormatter:
    def format_welcome_message(self) -> str:
        return """
ğŸ¯ <b>Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù†ÙˆØ¨Øªâ€ŒÚ¯ÛŒØ±ÛŒ Ù¾Ø°ÛŒØ±Ø´Û²Û´ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯!</b>

Ø§ÛŒÙ† Ø±Ø¨Ø§Øª Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ù…ÛŒâ€ŒÚ©Ù†Ø¯ ØªØ§ Ø§Ø² Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ Ø¯Ú©ØªØ±Ù‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±ØªØ§Ù† Ø¯Ø± Ø³Ø§ÛŒØª Ù¾Ø°ÛŒØ±Ø´Û²Û´ Ù…Ø·Ù„Ø¹ Ø´ÙˆÛŒØ¯.

ğŸ“‹ <b>Ø¯Ø³ØªÙˆØ±Ø§Øª Ù…ÙˆØ¬ÙˆØ¯:</b>
â€¢ /subscribe - Ø§ï¿½ï¿½ØªØ±Ø§Ú© Ø¯Ø± Ø¯Ú©ØªØ±
â€¢ /unsubscribe - Ù„ØºÙˆ Ø§Ø´ØªØ±Ø§Ú©
â€¢ /status - ÙˆØ¶Ø¹ÛŒØª Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§
â€¢ /help - Ø±Ø§Ù‡Ù†Ù…Ø§

âš¡ <b>ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§:</b>
â€¢ Ù†Ø¸Ø§Ø±Øª Û²Û´/Û· Ø¨Ø± Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
â€¢ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ ÙÙˆØ±ÛŒ (Ú©Ù…ØªØ± Ø§Ø² Û± Ø¯Ù‚ÛŒÙ‚Ù‡)
â€¢ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú†Ù†Ø¯ÛŒÙ† Ø¯Ú©ØªØ± Ù‡Ù…Ø²Ù…Ø§Ù†
â€¢ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯

Ø¨Ø±Ø§ÛŒ Ø´Ø±ÙˆØ¹ØŒ Ø§Ø² Ø¯Ø³ØªÙˆØ± /subscribe Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
        """
    
    def format_appointment_notification(self, doctor_info: Dict, appointment: Dict) -> str:
        return f"""
ğŸ¯ <b>Ù†ÙˆØ¨Øª Ø®Ø§Ù„ÛŒ Ù¾ÛŒØ¯Ø§ Ø´Ø¯!</b>

ğŸ‘¨â€âš•ï¸ <b>Ø¯Ú©ØªØ±:</b> {doctor_info['name']}
ğŸ¥ <b>ØªØ®ØµØµ:</b> {doctor_info['specialty']}
ğŸ“… <b>ØªØ§Ø±ÛŒØ®:</b> {appointment['date']}
ğŸ• <b>Ø³Ø§Ø¹Øª:</b> {appointment['time']}
ğŸ’° <b>Ù‡Ø²ÛŒÙ†Ù‡:</b> {appointment['price']}

â° <b>Ø²Ù…Ø§Ù† ÛŒØ§ÙØª Ù†ÙˆØ¨Øª:</b> {datetime.now().strftime('%H:%M:%S')}

âš ï¸ <b>ØªÙˆØ¬Ù‡:</b> Ø¨Ø±Ø§ÛŒ Ø±Ø²Ø±Ùˆ Ù†ÙˆØ¨ØªØŒ Ø³Ø±ÛŒØ¹Ø§Ù‹ Ø±ÙˆÛŒ Ø¯Ú©Ù…Ù‡ Ø²ÛŒØ± Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯.
        """
    
    def get_main_keyboard(self) -> InlineKeyboardMarkup:
        keyboard = [
            [InlineKeyboardButton("ğŸ” Ø§Ø´ØªØ±Ø§Ú© Ø¯Ø± Ø¯Ú©ØªØ±", callback_data="subscribe")],
            [InlineKeyboardButton("ğŸ“‹ ÙˆØ¶Ø¹ÛŒØª Ø§Ø´ØªØ±Ø§Ú©â€ŒÙ‡Ø§", callback_data="status")],
            [InlineKeyboardButton("âŒ Ù„ØºÙˆ Ø§Ø´ØªØ±Ø§Ú©", callback_data="unsubscribe")],
            [InlineKeyboardButton("â“ Ø±Ø§Ù‡Ù†Ù…Ø§", callback_data="help")]
        ]
        return InlineKeyboardMarkup(keyboard)
    
    def get_doctors_keyboard(self, doctors: List[Dict]) -> InlineKeyboardMarkup:
        keyboard = []
        for doctor in doctors:
            keyboard.append([
                InlineKeyboardButton(
                    f"ğŸ‘¨â€âš•ï¸ {doctor['name']}", 
                    callback_data=f"subscribe_doctor_{doctor['id']}"
                )
            ])
        keyboard.append([InlineKeyboardButton("ğŸ”™ Ø¨Ø§Ø²Ú¯Ø´Øª", callback_data="back_to_main")])
        return InlineKeyboardMarkup(keyboard)
    
    def get_appointment_keyboard(self, doctor_url: str) -> InlineKeyboardMarkup:
        keyboard = [
            [InlineKeyboardButton("ğŸ”— Ø±Ø²Ø±Ùˆ Ù†ÙˆØ¨Øª", url=doctor_url)],
            [InlineKeyboardButton("ğŸ”„ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø¯Ø¯", callback_data="refresh_appointments")]
        ]
        return InlineKeyboardMarkup(keyboard)
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Û³:**
- Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ú©Ø§Ù…Ù„ Ø¨Ø§ UI Ù¾ÛŒØ´Ø±ÙØªÙ‡
- Ø³ÛŒØ³ØªÙ… middleware Ùˆ logging
- Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
- ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ ØªØ¹Ø§Ù…Ù„ Ø¨Ø§ Ø±Ø¨Ø§Øª

---

### ğŸ“… ÙØ§Ø² Û´: Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ùˆ Cache Layer (Ø±ÙˆØ² Û·-Û¸)

#### Û´.Û± Database Models
```python
# src/database/models.py
from sqlalchemy import Column, Integer, String, Boolean, DateTime, ForeignKey, Text, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship
from datetime import datetime

Base = declarative_base()

class User(Base):
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True, index=True)
    telegram_id = Column(Integer, unique=True, index=True, nullable=False)
    username = Column(String(50), nullable=True)
    first_name = Column(String(100), nullable=True)
    last_name = Column(String(100), nullable=True)
    is_active = Column(Boolean, default=True)
    notification_preferences = Column(Text, nullable=True)  # JSON string
    created_at = Column(DateTime, default=datetime.utcnow)
    last_activity = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    subscriptions = relationship("Subscription", back_populates="user")

class Doctor(Base):
    __tablename__ = "doctors"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(100), nullable=False)
    url = Column(String(500), unique=True, nullable=False)
    specialty = Column(String(100), nullable=True)
    location = Column(String(200), nullable=True)
    is_active = Column(Boolean, default=True)
    last_checked = Column(DateTime, nullable=True)
    check_interval = Column(Integer, default=30)  # seconds
    success_rate = Column(Float, default=1.0)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    subscriptions = relationship("Subscription", back_populates="doctor")
    appointments = relationship("Appointment", back_populates="doctor")

class Subscription(Base):
    __tablename__ = "subscriptions"
    
    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    doctor_id = Column(Integer, ForeignKey("doctors.id"), nullable=False)
    is_active = Column(Boolean, default=True)
    notification_count = Column(Integer, default=0)
    last_notification = Column(DateTime, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    user = relationship("User", back_populates="subscriptions")
    doctor = relationship("Doctor", back_populates="subscriptions")

class Appointment(Base):
    __tablename__ = "appointments"
    
    id = Column(Integer, primary_key=True, index=True)
    doctor_id = Column(Integer, ForeignKey("doctors.id"), nullable=False)
    appointment_date = Column(String(20), nullable=False)
    appointment_time = Column(String(20), nullable=False)
    price = Column(String(50), nullable=True)
    is_available = Column(Boolean, default=True)
    first_seen = Column(DateTime, default=datetime.utcnow)
    last_seen = Column(DateTime, default=datetime.utcnow)
    notification_sent = Column(Boolean, default=False)
    
    # Relationships
    doctor = relationship("Doctor", back_populates="appointments")

class SystemLog(Base):
    __tablename__ = "system_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    level = Column(String(20), nullable=False)
    message = Column(Text, nullable=False)
    component = Column(String(50), nullable=True)
    doctor_id = Column(Integer, ForeignKey("doctors.id"), nullable=True)
    user_id = Column(Integer, ForeignKey("users.id"), nullable=True)
    metadata = Column(Text, nullable=True)  # JSON string
    created_at = Column(DateTime, default=datetime.utcnow)
```

#### Û´.Û² Repository Pattern
```python
# src/database/repositories.py
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_
from typing import List, Optional, Dict, Any
from .models import User, Doctor, Subscription, Appointment
from datetime import datetime, timedelta

class UserRepository:
    def __init__(self, db: Session):
        self.db = db
    
    async def create_user(self, telegram_id: int, username: str = None, 
                         first_name: str = None, last_name: str = None) -> User:
        user = User(
            telegram_id=telegram_id,
            username=username,
            first_name=first_name,
            last_name=last_name
        )
        self.db.add(user)
        self.db.commit()
        self.db.refresh(user)
        return user
    
    async def get_user_by_telegram_id(self, telegram_id: int) -> Optional[User]:
        return self.db.query(User).filter(User.telegram_id == telegram_id).first()
    
    async def get_active_subscribers_for_doctor(self, doctor_id: int) -> List[User]:
        return self.db.query(User).join(Subscription).filter(
            and_(
                Subscription.doctor_id == doctor_id,
                Subscription.is_active == True,
                User.is_active == True
            )
        ).all()

class DoctorRepository:
    def __init__(self, db: Session):
        self.db = db
    
    async def create_doctor(self, name: str, url: str, specialty: str = None, 
                           location: str = None) -> Doctor:
        doctor = Doctor(
            name=name,
            url=url,
            specialty=specialty,
            location=location
        )
        self.db.add(doctor)
        self.db.commit()
        self.db.refresh(doctor)
        return doctor
    
    async def get_active_doctors(self) -> List[Doctor]:
        return self.db.query(Doctor).filter(Doctor.is_active == True).all()
    
    async def update_last_checked(self, doctor_id: int, success: bool = True):
        doctor = self.db.query(Doctor).filter(Doctor.id == doctor_id).first()
        if doctor:
            doctor.last_checked = datetime.utcnow()
            if success:
                doctor.success_rate = min(1.0, doctor.success_rate + 0.01)
            else:
                doctor.success_rate = max(0.0, doctor.success_rate - 0.05)
            self.db.commit()

class AppointmentRepository:
    def __init__(self, db: Session):
        self.db = db
    
    async def save_appointments(self, doctor_id: int, appointments: List[Dict[str, Any]]):
        # Ø­Ø°Ù Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ
        self.db.query(Appointment).filter(Appointment.doctor_id == doctor_id).delete()
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯
        for apt in appointments:
            appointment = Appointment(
                doctor_id=doctor_id,
                appointment_date=apt['date'],
                appointment_time=apt['time'],
                price=apt.get('price', 'Ù†Ø§Ù…Ø´Ø®Øµ'),
                is_available=True
            )
            self.db.add(appointment)
        
        self.db.commit()
    
    async def get_new_appointments(self, doctor_id: int, 
                                  since: datetime = None) -> List[Appointment]:
        query = self.db.query(Appointment).filter(
            and_(
                Appointment.doctor_id == doctor_id,
                Appointment.is_available == True,
                Appointment.notification_sent == False
            )
        )
        
        if since:
            query = query.filter(Appointment.first_seen >= since)
        
        return query.all()
```

#### Û´.Û³ Redis Cache Manager
```python
# src/cache/cache_manager.py
import redis.asyncio as redis
import json
from typing import Any, Optional, List, Dict
from datetime import timedelta
import structlog

logger = structlog.get_logger(__name__)

class CacheManager:
    def __init__(self, redis_url: str):
        self.redis_url = redis_url
        self.redis_client = None
    
    async def connect(self):
        self.redis_client = redis.from_url(self.redis_url, decode_responses=True)
        await self.redis_client.ping()
        logger.info("Connected to Redis successfully")
    
    async def disconnect(self):
        if self.redis_client:
            await self.redis_client.close()
    
    async def set_appointments(self, doctor_id: int, appointments: List[Dict], 
                              expire: int = 300):
        """Ø°Ø®ÛŒØ±Ù‡ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ Ø¯Ø± cache"""
        key = f"appointments:doctor:{doctor_id}"
        value = json.dumps(appointments, ensure_ascii=False)
        await self.redis_client.setex(key, expire, value)
    
    async def get_appointments(self, doctor_id: int) -> Optional[List[Dict]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ Ø§Ø² cache"""
        key = f"appointments:doctor:{doctor_id}"
        value = await self.redis_client.get(key)
        if value:
            return json.loads(value)
        return None
    
    async def set_doctor_status(self, doctor_id: int, status: str, expire: int = 60):
        """ÙˆØ¶Ø¹ÛŒØª Ø¯Ú©ØªØ± (checking, success, error)"""
        key = f"doctor:status:{doctor_id}"
        await self.redis_client.setex(key, expire, status)
    
    async def get_doctor_status(self, doctor_id: int) -> Optional[str]:
        key = f"doctor:status:{doctor_id}"
        return await self.redis_client.get(key)
    
    async def increment_notification_count(self, user_id: int, doctor_id: int):
        """Ø´Ù…Ø§Ø±Ø´ ØªØ¹Ø¯Ø§Ø¯ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒâ€ŒÙ‡Ø§"""
        key = f"notifications:{user_id}:{doctor_id}"
        await self.redis_client.incr(key)
        await self.redis_client.expire(key, 86400)  # 24 hours
    
    async def get_notification_count(self, user_id: int, doctor_id: int) -> int:
        key = f"notifications:{user_id}:{doctor_id}"
        count = await self.redis_client.get(key)
        return int(count) if count else 0
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Û´:**
- Ù…ï¿½ï¿½Ù„â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©Ø§Ù…Ù„
- Repository pattern
- Redis cache layer
- Migration scripts
- ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ Ø¯ÛŒØªØ§Ø¨ÛŒØ³

---

### ğŸ“… ÙØ§Ø² Ûµ: Async Scheduler Ùˆ Orchestration (Ø±ÙˆØ² Û¹-Û±Û°)

#### Ûµ.Û± Task Scheduler
```python
# src/scheduler/task_scheduler.py
import asyncio
from typing import List, Dict, Callable, Any
from datetime import datetime, timedelta
import structlog
from ..scraper.paziresh_scraper import PazireshScraper
from ..database.repositories import DoctorRepository, AppointmentRepository, UserRepository
from ..telegram.bot_handler import TelegramBot
from ..cache.cache_manager import CacheManager
from ..monitoring.metrics import MetricsCollector

logger = structlog.get_logger(__name__)

class AppointmentScheduler:
    def __init__(self, 
                 scraper: PazireshScraper,
                 telegram_bot: TelegramBot,
                 cache_manager: CacheManager,
                 doctor_repo: DoctorRepository,
                 appointment_repo: AppointmentRepository,
                 user_repo: UserRepository,
                 metrics: MetricsCollector):
        
        self.scraper = scraper
        self.telegram_bot = telegram_bot
        self.cache_manager = cache_manager
        self.doctor_repo = doctor_repo
        self.appointment_repo = appointment_repo
        self.user_repo = user_repo
        self.metrics = metrics
        
        self.running = False
        self.tasks = {}
        self.check_interval = 30  # seconds
    
    async def start(self):
        """Ø´Ø±ÙˆØ¹ scheduler"""
        self.running = True
        logger.info("Starting appointment scheduler")
        
        # Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª Ø¯Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ¹Ø§Ù„
        doctors = await self.doctor_repo.get_active_doctors()
        
        # Ø§ÛŒØ¬Ø§Ø¯ task Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø¯Ú©ØªØ±
        for doctor in doctors:
            task = asyncio.create_task(self.monitor_doctor(doctor))
            self.tasks[doctor.id] = task
        
        # Task Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…
        health_task = asyncio.create_task(self.health_monitor())
        self.tasks['health'] = health_task
        
        # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… task Ù‡Ø§
        await asyncio.gather(*self.tasks.values(), return_exceptions=True)
    
    async def stop(self):
        """ØªÙˆÙ‚Ù scheduler"""
        self.running = False
        logger.info("Stopping appointment scheduler")
        
        # Ù„ØºÙˆ ØªÙ…Ø§Ù… task Ù‡Ø§
        for task in self.tasks.values():
            task.cancel()
        
        # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø´Ø¯Ù† task Ù‡Ø§
        await asyncio.gather(*self.tasks.values(), return_exceptions=True)
    
    async def monitor_doctor(self, doctor):
        """Ù†Ø¸Ø§Ø±Øª Ù…Ø¯Ø§ÙˆÙ… Ø¨Ø± ÛŒÚ© Ø¯Ú©ØªØ±"""
        logger.info(f"Starting monitoring for doctor {doctor.name}", doctor_id=doctor.id)
        
        while self.running:
            try:
                start_time = datetime.utcnow()
                
                # ØªÙ†Ø¸ÛŒÙ… ÙˆØ¶Ø¹ÛŒØª Ø¯Ø± cache
                await self.cache_manager.set_doctor_status(doctor.id, "checking")
                
                # Ø¨Ø±Ø±Ø³ÛŒ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
                async with self.scraper as scraper:
                    appointments = await scraper.scrape_appointments(doctor.url)
                
                # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
                cached_appointments = await self.cache_manager.get_appointments(doctor.id)
                new_appointments = self.find_new_appointments(appointments, cached_appointments)
                
                if new_appointments:
                    logger.info(f"Found {len(new_appointments)} new appointments", 
                               doctor_id=doctor.id)
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                    await self.appointment_repo.save_appointments(doctor.id, appointments)
                    
                    # Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
                    await self.notify_subscribers(doctor, new_appointments)
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ cache
                await self.cache_manager.set_appointments(doctor.id, appointments)
                await self.cache_manager.set_doctor_status(doctor.id, "success")
                
                # Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø± Ø¯Ú©ØªØ±
                await self.doctor_repo.update_last_checked(doctor.id, success=True)
                
                # Ø«Ø¨Øª metrics
                processing_time = (datetime.utcnow() - start_time).total_seconds()
                self.metrics.record_scraping_duration(doctor.id, processing_time)
                self.metrics.record_appointments_found(doctor.id, len(appointments))
                
                logger.info(f"Successfully checked doctor {doctor.name}", 
                           doctor_id=doctor.id, 
                           appointments_count=len(appointments),
                           processing_time=processing_time)
                
            except Exception as e:
                logger.error(f"Error monitoring doctor {doctor.name}", 
                           doctor_id=doctor.id, 
                           error=str(e))
                
                await self.cache_manager.set_doctor_status(doctor.id, "error")
                await self.doctor_repo.update_last_checked(doctor.id, success=False)
                self.metrics.record_scraping_error(doctor.id)
            
            # Ø§Ù†ØªØ¸Ø§Ø± ØªØ§ Ú†Ú© Ø¨Ø¹Ø¯ÛŒ
            await asyncio.sleep(self.check_interval)
    
    def find_new_appointments(self, current: List[Dict], cached: List[Dict]) -> List[Dict]:
        """ÛŒØ§ÙØªÙ† Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯"""
        if not cached:
            return current
        
        cached_set = {(apt['date'], apt['time']) for apt in cached}
        new_appointments = []
        
        for apt in current:
            if (apt['date'], apt['time']) not in cached_set:
                new_appointments.append(apt)
        
        return new_appointments
    
    async def notify_subscribers(self, doctor, appointments: List[Dict]):
        """Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¨Ù‡ Ù…Ø´ØªØ±Ú©ÛŒÙ†"""
        subscribers = await self.user_repo.get_active_subscribers_for_doctor(doctor.id)
        
        for user in subscribers:
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªØ¹Ø¯Ø§Ø¯ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ
            notification_count = await self.cache_manager.get_notification_count(
                user.telegram_id, doctor.id
            )
            
            if notification_count < 10:  # Ø­Ø¯Ø§Ú©Ø«Ø± 10 Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ø¯Ø± Ø±ÙˆØ²
                for appointment in appointments:
                    try:
                        await self.telegram_bot.notify_appointment_available(
                            user.telegram_id, 
                            {
                                'name': doctor.name,
                                'specialty': doctor.specialty,
                                'url': doctor.url
                            },
                            appointment
                        )
                        
                        await self.cache_manager.increment_notification_count(
                            user.telegram_id, doctor.id
                        )
                        
                        self.metrics.record_notification_sent(user.telegram_id, doctor.id)
                        
                    except Exception as e:
                        logger.error("Failed to send notification", 
                                   user_id=user.telegram_id, 
                                   doctor_id=doctor.id, 
                                   error=str(e))
    
    async def health_monitor(self):
        """Ù†Ø¸Ø§Ø±Øª Ø¨Ø± Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…"""
        while self.running:
            try:
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Redis
                await self.cache_manager.redis_client.ping()
                
                # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø¯ÛŒØªØ§Ø¨ÛŒØ³
                doctors = await self.doctor_repo.get_active_doctors()
                
                # Ø¨Ø±Ø±Ø³ÛŒ task Ù‡Ø§ÛŒ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§
                active_tasks = sum(1 for task in self.tasks.values() if not task.done())
                
                logger.info("System health check", 
                           active_doctors=len(doctors),
                           active_tasks=active_tasks)
                
                self.metrics.record_system_health(len(doctors), active_tasks)
                
            except Exception as e:
                logger.error("Health check failed", error=str(e))
            
            await asyncio.sleep(60)  # Ù‡Ø± Ø¯Ù‚ÛŒÙ‚Ù‡
```

#### Ûµ.Û² Metrics Collector
```python
# src/monitoring/metrics.py
from prometheus_client import Counter, Histogram, Gauge, start_http_server
from typing import Dict, Any
import time

class MetricsCollector:
    def __init__(self):
        # Counters
        self.scraping_total = Counter('scraping_requests_total', 
                                     'Total scraping requests', 
                                     ['doctor_id', 'status'])
        
        self.notifications_sent = Counter('notifications_sent_total',
                                         'Total notifications sent',
                                         ['user_id', 'doctor_id'])
        
        self.appointments_found = Counter('appointments_found_total',
                                         'Total appointments found',
                                         ['doctor_id'])
        
        # Histograms
        self.scraping_duration = Histogram('scraping_duration_seconds',
                                          'Time spent scraping',
                                          ['doctor_id'])
        
        # Gauges
        self.active_doctors = Gauge('active_doctors_count',
                                   'Number of active doctors being monitored')
        
        self.active_tasks = Gauge('active_tasks_count',
                                 'Number of active monitoring tasks')
        
        self.system_uptime = Gauge('system_uptime_seconds',
                                  'System uptime in seconds')
        
        self.start_time = time.time()
    
    def record_scraping_duration(self, doctor_id: int, duration: float):
        self.scraping_duration.labels(doctor_id=str(doctor_id)).observe(duration)
        self.scraping_total.labels(doctor_id=str(doctor_id), status='success').inc()
    
    def record_scraping_error(self, doctor_id: int):
        self.scraping_total.labels(doctor_id=str(doctor_id), status='error').inc()
    
    def record_notification_sent(self, user_id: int, doctor_id: int):
        self.notifications_sent.labels(
            user_id=str(user_id), 
            doctor_id=str(doctor_id)
        ).inc()
    
    def record_appointments_found(self, doctor_id: int, count: int):
        self.appointments_found.labels(doctor_id=str(doctor_id)).inc(count)
    
    def record_system_health(self, doctors_count: int, tasks_count: int):
        self.active_doctors.set(doctors_count)
        self.active_tasks.set(tasks_count)
        self.system_uptime.set(time.time() - self.start_time)
    
    def start_metrics_server(self, port: int = 8000):
        start_http_server(port)
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Ûµ:**
- Async scheduler Ú©Ø§Ù…Ù„
- Ø³ÛŒØ³ØªÙ… monitoring Ùˆ metrics
- Health check mechanism
- Performance optimization
- ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ load testing

---

### ğŸ“… ÙØ§Ø² Û¶: ØªØ³ØªØŒ Deployment Ùˆ Documentation (Ø±ÙˆØ² Û±Û±-Û±Û´)

#### Û¶.Û± Test Suite
```python
# tests/integration/test_appointment_flow.py
import pytest
import asyncio
from unittest.mock import AsyncMock, MagicMock
from src.scheduler.task_scheduler import AppointmentScheduler

@pytest.mark.asyncio
async def test_complete_appointment_flow():
    """ØªØ³Øª Ú©Ø§Ù…Ù„ ÙØ±Ø¢ÛŒÙ†Ø¯ ÛŒØ§ÙØªÙ† Ùˆ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ Ù†ÙˆØ¨Øª"""
    
    # Mock dependencies
    scraper = AsyncMock()
    telegram_bot = AsyncMock()
    cache_manager = AsyncMock()
    doctor_repo = AsyncMock()
    appointment_repo = AsyncMock()
    user_repo = AsyncMock()
    metrics = MagicMock()
    
    # Setup test data
    test_doctor = MagicMock()
    test_doctor.id = 1
    test_doctor.name = "Ø¯Ú©ØªØ± ØªØ³Øª"
    test_doctor.url = "https://test.com"
    
    test_appointments = [
        {'date': '1403/01/15', 'time': '10:00', 'price': '200000'},
        {'date': '1403/01/15', 'time': '10:30', 'price': '200000'}
    ]
    
    test_users = [MagicMock()]
    test_users[0].telegram_id = 123456789
    
    # Configure mocks
    scraper.scrape_appointments.return_value = test_appointments
    cache_manager.get_appointments.return_value = []  # No cached appointments
    user_repo.get_active_subscribers_for_doctor.return_value = test_users
    cache_manager.get_notification_count.return_value = 0
    
    # Create scheduler
    scheduler = AppointmentScheduler(
        scraper, telegram_bot, cache_manager,
        doctor_repo, appointment_repo, user_repo, metrics
    )
    
    # Test the monitoring process
    await scheduler.monitor_doctor(test_doctor)
    
    # Verify scraping was called
    scraper.scrape_appointments.assert_called_once_with(test_doctor.url)
    
    # Verify appointments were saved
    appointment_repo.save_appointments.assert_called_once()
    
    # Verify notifications were sent
    assert telegram_bot.notify_appointment_available.call_count == 2
```

#### Û¶.Û² Docker Configuration
```dockerfile
# docker/Dockerfile
FROM python:3.9-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    wget \
    gnupg \
    unzip \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Playwright browsers
RUN pip install playwright==1.40.0
RUN playwright install chromium
RUN playwright install-deps

# Set working directory
WORKDIR /app

# Copy requirements
COPY requirements/ ./requirements/
RUN pip install --no-cache-dir -r requirements/prod.txt

# Copy application code
COPY src/ ./src/
COPY config/ ./config/
COPY main.py ./

# Create data directory
RUN mkdir -p /app/data

# Set environment variables
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["python", "main.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: docker/Dockerfile
    container_name: p24-slothunter
    restart: unless-stopped
    environment:
      - DATABASE_URL=postgresql://user:password@postgres:5432/p24_slothunter
      - REDIS_URL=redis://redis:6379
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_ADMIN_CHAT_ID=${TELEGRAM_ADMIN_CHAT_ID}
      - LOG_LEVEL=INFO
      - ENABLE_METRICS=true
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    ports:
      - "8000:8000"  # Metrics endpoint
    depends_on:
      - postgres
      - redis
    networks:
      - p24-network

  postgres:
    image: postgres:15-alpine
    container_name: p24-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=p24_slothunter
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    networks:
      - p24-network

  redis:
    image: redis:7-alpine
    container_name: p24-redis
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - p24-network

  prometheus:
    image: prom/prometheus:latest
    container_name: p24-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - p24-network

  grafana:
    image: grafana/grafana:latest
    container_name: p24-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana:/etc/grafana/provisioning
    networks:
      - p24-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  p24-network:
    driver: bridge
```

#### Û¶.Û³ Deployment Scripts
```bash
#!/bin/bash
# scripts/deploy.sh

set -e

echo "ğŸš€ Starting P24_SlotHunter deployment..."

# Check if .env file exists
if [ ! -f .env ]; then
    echo "âŒ .env file not found. Please create it first."
    exit 1
fi

# Pull latest changes
echo "ğŸ“¥ Pulling latest changes..."
git pull origin main

# Build and start services
echo "ğŸ”¨ Building and starting services..."
docker-compose down
docker-compose build --no-cache
docker-compose up -d

# Wait for services to be ready
echo "â³ Waiting for services to be ready..."
sleep 30

# Run database migrations
echo "ğŸ—„ï¸ Running database migrations..."
docker-compose exec app python -m alembic upgrade head

# Check service health
echo "ğŸ¥ Checking service health..."
if curl -f http://localhost:8000/health; then
    echo "âœ… Deployment successful!"
else
    echo "âŒ Health check failed!"
    docker-compose logs app
    exit 1
fi

echo "ğŸ‰ P24_SlotHunter is now running!"
echo "ğŸ“Š Metrics: http://localhost:9090"
echo "ğŸ“ˆ Grafana: http://localhost:3000"
```

#### Û¶.Û´ Main Application Entry Point
```python
# main.py
import asyncio
import signal
import sys
from contextlib import asynccontextmanager
from src.core.config import settings
from src.database.database import DatabaseManager
from src.cache.cache_manager import CacheManager
from src.scraper.paziresh_scraper import PazireshScraper
from src.telegram.bot_handler import TelegramBot
from src.scheduler.task_scheduler import AppointmentScheduler
from src.monitoring.logger import setup_logging
from src.monitoring.metrics import MetricsCollector
import structlog

# Setup logging
setup_logging(settings.log_level)
logger = structlog.get_logger(__name__)

class Application:
    def __init__(self):
        self.db_manager = None
        self.cache_manager = None
        self.telegram_bot = None
        self.scheduler = None
        self.metrics = None
        self.running = False
    
    async def startup(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø§Ø¬Ø²Ø§ÛŒ Ø³ÛŒØ³ØªÙ…"""
        logger.info("Starting P24_SlotHunter application")
        
        try:
            # Database
            self.db_manager = DatabaseManager(settings.database_url)
            await self.db_manager.connect()
            
            # Cache
            self.cache_manager = CacheManager(settings.redis_url)
            await self.cache_manager.connect()
            
            # Metrics
            if settings.enable_metrics:
                self.metrics = MetricsCollector()
                self.metrics.start_metrics_server(8000)
            
            # Telegram Bot
            from src.database.repositories import UserRepository
            user_repo = UserRepository(self.db_manager.get_session())
            self.telegram_bot = TelegramBot(settings.telegram_bot_token, user_repo)
            await self.telegram_bot.setup()
            
            # Scheduler
            from src.database.repositories import DoctorRepository, AppointmentRepository
            doctor_repo = DoctorRepository(self.db_manager.get_session())
            appointment_repo = AppointmentRepository(self.db_manager.get_session())
            
            scraper = PazireshScraper()
            
            self.scheduler = AppointmentScheduler(
                scraper=scraper,
                telegram_bot=self.telegram_bot,
                cache_manager=self.cache_manager,
                doctor_repo=doctor_repo,
                appointment_repo=appointment_repo,
                user_repo=user_repo,
                metrics=self.metrics or MetricsCollector()
            )
            
            self.running = True
            logger.info("Application startup completed successfully")
            
        except Exception as e:
            logger.error("Failed to start application", error=str(e))
            await self.shutdown()
            raise
    
    async def shutdown(self):
        """Ø®Ø§Ù…ÙˆØ´ Ú©Ø±Ø¯Ù† Ø³ÛŒØ³ØªÙ…"""
        logger.info("Shutting down P24_SlotHunter application")
        
        self.running = False
        
        if self.scheduler:
            await self.scheduler.stop()
        
        if self.telegram_bot and self.telegram_bot.app:
            await self.telegram_bot.app.stop()
        
        if self.cache_manager:
            await self.cache_manager.disconnect()
        
        if self.db_manager:
            await self.db_manager.disconnect()
        
        logger.info("Application shutdown completed")
    
    async def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡"""
        await self.startup()
        
        # Setup signal handlers
        def signal_handler(signum, frame):
            logger.info(f"Received signal {signum}, shutting down...")
            asyncio.create_task(self.shutdown())
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        try:
            # Start telegram bot
            bot_task = asyncio.create_task(self.telegram_bot.app.run_polling())
            
            # Start scheduler
            scheduler_task = asyncio.create_task(self.scheduler.start())
            
            # Wait for tasks
            await asyncio.gather(bot_task, scheduler_task, return_exceptions=True)
            
        except Exception as e:
            logger.error("Application error", error=str(e))
        finally:
            await self.shutdown()

async def main():
    app = Application()
    await app.run()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("Application interrupted by user")
    except Exception as e:
        logger.error("Application failed", error=str(e))
        sys.exit(1)
```

**ØªØ­ÙˆÛŒÙ„ÛŒ ÙØ§Ø² Û¶:**
- Test suite Ú©Ø§Ù…Ù„
- Docker containerization
- CI/CD pipeline
- Monitoring dashboard
- Documentation Ú©Ø§Ù…Ù„
- Production deployment

---

## ğŸ“Š Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ KPIs

### Performance Metrics
- **Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´:** < 3 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ 3 Ø¯Ú©ØªØ±
- **Response Time:** < 5 Ø«Ø§Ù†ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ
- **Uptime:** > 99%
- **False Positive Rate:** < 5%
- **Memory Usage:** < 512MB
- **CPU Usage:** < 50%

### Functional Requirements
- âœ… ØªØ´Ø®ÛŒØµ ØµØ­ÛŒØ­ Ù†ÙˆØ¨Øªâ€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù„ÛŒ
- âœ… Ø§Ø·Ù„Ø§Ø¹â€ŒØ±Ø³Ø§Ù†ÛŒ ÙÙˆØ±ÛŒ (< 1 Ø¯Ù‚ÛŒÙ‚Ù‡)
- âœ… Ù…Ø¯ÛŒØ±ÛŒØª Ú†Ù†Ø¯ÛŒÙ† Ú©Ø§Ø±Ø¨Ø± Ù‡Ù…Ø²Ù…Ø§Ù†
- âœ… Restart Ø®ÙˆØ¯Ú©Ø§Ø± Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
- âœ… Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯

### Security & Compliance
- âœ… Rate limiting (Ø­Ø¯Ø§Ú©Ø«Ø± 2 Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø«Ø§Ù†ÛŒÙ‡)
- âœ… Ø±Ù…Ø²Ú¯Ø°Ø§Ø±ÛŒ API keys
- âœ… Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
- âœ… HTTPS Ø¨Ø±Ø§ÛŒ ØªÙ…Ø§Ù… Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª
- âœ… Backup Ù…Ù†Ø¸Ù… Ø¯ÛŒØªØ§Ø¨ÛŒØ³

---

## ğŸ›  Ù…Ù†Ø§Ø¨Ø¹ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²

### Infrastructure
- **Server:** VPS Ø¨Ø§ 2GB RAM Ùˆ 2 CPU cores (Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡)
- **Storage:** 20GB Ø¨Ø±Ø§ÛŒ logsØŒ database Ùˆ cache
- **Network:** Ø§ØªØµØ§Ù„ Ù¾Ø§ÛŒØ¯Ø§Ø± Ø¨Ù‡ Ø§ÛŒÙ†ØªØ±Ù†Øª Ø¨Ø§ Ø­Ø¯Ø§Ù‚Ù„ 10Mbps
- **Monitoring:** Prometheus + Grafana stack

### Development Tools
- **IDE:** VS Code / PyCharm
- **Version Control:** Git + GitHub
- **CI/CD:** GitHub Actions
- **Testing:** pytest + coverage
- **Code Quality:** black + flake8 + mypy

---

## ğŸš¨ Ù†Ú©Ø§Øª Ù…Ù‡Ù… Ùˆ Ø¨Ù‡ØªØ±ÛŒÙ† Ø´ÛŒÙˆÙ‡â€ŒÙ‡Ø§

### Critical Success Factors
1. **ØªØ³Øª Ù…Ø¯Ø§ÙˆÙ…:** Ø³Ø§Ø®ØªØ§Ø± Ø³Ø§ÛŒØª Ù…Ù…Ú©Ù† Ø§Ø³Øª ØªØºÛŒÛŒØ± Ú©Ù†Ø¯
2. **Graceful Degradation:** Ø³ÛŒØ³ØªÙ… Ø¨Ø§ÛŒØ¯ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§ Ø¨Ù‡ Ø¢Ø±Ø§Ù…ÛŒ Ù…ØªÙˆÙ‚Ù Ø´ÙˆØ¯
3. **Rate Limiting:** Ø­ØªÙ…Ø§Ù‹ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±Ø§ Ø±Ø¹Ø§ÛŒØª Ú©Ù†ÛŒØ¯
4. **User Experience:** Ø±Ø§Ø¨Ø· Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù… Ø¨Ø§ÛŒØ¯ Ø³Ø§Ø¯Ù‡ Ùˆ Ú©Ø§Ø±Ø¨Ø±Ù¾Ø³Ù†Ø¯ Ø¨Ø§Ø´Ø¯
5. **Monitoring:** Ù†Ø¸Ø§Ø±Øª Ù…Ø¯Ø§ÙˆÙ… Ø¨Ø± Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ… Ø¶Ø±ÙˆØ±ÛŒ Ø§Ø³Øª

### Risk Mitigation
- **Website Changes:** Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ flexible selectors
- **Rate Limiting:** Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² exponential backoff
- **Server Downtime:** Circuit breaker pattern
- **Data Loss:** Backup strategy Ùˆ replication
- **Security:** Regular security audits

### Maintenance Strategy
- **Weekly:** Ø¨Ø±Ø±Ø³ÛŒ logs Ùˆ performance metrics
- **Monthly:** Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ dependencies
- **Quarterly:** Security audit Ùˆ penetration testing
- **Yearly:** Architecture review Ùˆ optimization

---

## ğŸ“ˆ Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ (Post-MVP)

### Phase 7: Advanced Features
- **Smart Scheduling:** ML-based optimal check intervals
- **Multi-City Support:** Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ø´Ù‡Ø±Ù‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
- **Appointment Booking:** Ø±Ø²Ø±Ùˆ Ø®ÙˆØ¯Ú©Ø§Ø± Ù†ÙˆØ¨Øª
- **Mobile App:** Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Ù…ÙˆØ¨Ø§ÛŒÙ„ native

### Phase 8: Scale & Optimization
- **Microservices:** ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ architecture Ù…ÛŒÚ©Ø±ÙˆØ³Ø±ÙˆÛŒØ³
- **Load Balancing:** Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² traffic Ø¨Ø§Ù„Ø§
- **Multi-Region:** deployment Ø¯Ø± Ú†Ù†Ø¯ÛŒÙ† Ù…Ù†Ø·Ù‚Ù‡
- **Advanced Analytics:** ØªØ­Ù„ÛŒÙ„ Ø±ÙØªØ§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†

---

## ğŸ¯ Ø®Ù„Ø§ØµÙ‡ Ùˆ Ù†ØªÛŒØ¬Ù‡â€ŒÚ¯ÛŒØ±ÛŒ

Ø§ÛŒÙ† Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ Ø¬Ø§Ù…Ø¹ Ø¨Ø±Ø§ÛŒ ØªÙˆØ³Ø¹Ù‡ P24_SlotHunter Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ ØªØ§:

1. **Ú©ÛŒÙÛŒØª Ø¨Ø§Ù„Ø§:** Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¨Ù‡ØªØ±ÛŒÙ† practices Ùˆ patterns
2. **Ù…Ù‚ÛŒØ§Ø³â€ŒÙ¾Ø°ÛŒØ±ÛŒ:** Ù‚Ø§Ø¨Ù„ÛŒØª Ø±Ø´Ø¯ Ùˆ ØªÙˆØ³Ø¹Ù‡ Ø¯Ø± Ø¢ÛŒÙ†Ø¯Ù‡
3. **Ù‚Ø§Ø¨Ù„ÛŒØª Ø§Ø·Ù…ÛŒÙ†Ø§Ù†:** uptime Ø¨Ø§Ù„Ø§ Ùˆ error handling Ù…Ù†Ø§Ø³Ø¨
4. **Ø§Ù…Ù†ÛŒØª:** Ø±Ø¹Ø§ÛŒØª Ø§ØµÙˆÙ„ Ø§Ù…Ù†ÛŒØªÛŒ Ùˆ Ø­Ø±ÛŒÙ… Ø®ØµÙˆØµÛŒ
5. **Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¢Ø³Ø§Ù†:** Ú©Ø¯ ØªÙ…ÛŒØ² Ùˆ Ù…Ø³ØªÙ†Ø¯Ø§Øª Ú©Ø§Ù…Ù„

Ø¨Ø§ Ù¾ÛŒØ±ÙˆÛŒ Ø§Ø² Ø§ÛŒÙ† Ù†Ù‚Ø´Ù‡ Ø±Ø§Ù‡ØŒ Ù¾Ø±ÙˆÚ˜Ù‡ P24_SlotHunter Ù‚Ø§Ø¯Ø± Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯ Ø¨Ù‡ Ù‡Ø¯Ù Ø³Ø±Ø¹Øª Û¹ Ø§Ø² Û±Û° Ø¯Ø³Øª ÛŒØ§Ø¨Ø¯ Ùˆ Ø®Ø¯Ù…Ø§Øª Ø¨Ø§Ú©ÛŒÙÛŒØªÛŒ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ø§Ø±Ø§Ø¦Ù‡ Ø¯Ù‡Ø¯.

---

**ØªØ§Ø±ÛŒØ® Ø§ÛŒØ¬Ø§Ø¯:** {datetime.now().strftime('%Y/%m/%d')}  
**Ù†Ø³Ø®Ù‡:** 1.0  
**ÙˆØ¶Ø¹ÛŒØª:** Ready for Implementation
